---
layout: posts
title: "Repeated Measures Regression"
date: 2017-03-28
---

Most tutorials on statistics and data science begin with a regression example. This totally makes sense: regression is simple enough to describe in non-mathematical language and involves interactions across two dimensions, so it's easy to visualize. And while I find that most researchers in psychology and computer science are intimately familiar with general linear regression, the question I get most often is "how do I account for repeated measurements from the same participant." I'll tackle the basics of repeated-measures ANOVA in this tutorial and give a few tips and tricks for easy analysis in R using R Markdown. I'm going to assume the reader has some familiarity with linear regression, but we'll go over some basics just to refresh.

## Regression

Say that we have two continuous measures -- numerical data that can theoretically be measured in infinitely small units. These can be any kind of real numbers, but regression is best suited for ratio numbers, such as age in months, height in inches, time in milliseconds, or scores on an IQ test. Let's go ahead and say that we have two relatively intuitive scores, like age and height. It is relatively intuitive that until late adolescence, age and height are highly related. The first thing we can look at is the correlation between items.

```{r}
age <-    c(10,10,10,10,10,
            11,11,11,11,11,
            12,12,12,12,12,
            13,13,13,13,13,
            14,14,14,14,14)
height <- c(54,58,56,51,52,
            56,58,62,53,52,
            60,60,63,53,53,
            62,60,65,55,54,
            64,61,68,56,54)
cor(age,height)
cor.test(age,height)
```
Furthermore, we can use linear regression to find the line that passes as close to all the points in our dataset. This line serves two purposes: first, like the correlation test, we can judge the likelihood that one item affects another item. However in this case we can assume direct causal relationships between items. Second, we can use this model to predict future data.

For the sake of consistency, I'm using regression and not Analysis of Variance (ANOVA). ANOVA is a special case of regression for categorical data (e.g., conditions or groups). It behaves identically to regression when using continuous data. *NOTE*: Many ANOVA functions in R or other statistical software output the results of ANOVAs as $F_{df1,df2}$ scores, whereas many regression functions give output as $t_{df}$. In those cases where $df1 = 1$, $F_{df1=1,df2} = t_{df2}^2$.

You can *totally* do repeated measures ANOVAS using the aov package, but things get a little complicated when trying to account for covariates. I'll show you how to do both repeated-measures regression and repeated-measures ANOVA, but we'll concentrate on regression for more complicated models.

As always, we begin by visualizing the data.

```{r,echo=TRUE}
library(ggplot2)
qplot(x = age, y = height, geom = "point") + geom_smooth(method='lm')
```

We then run a simple linear regression model predicting height from age.

```{r}
fit1 <- lm(height ~ age)
summary(fit1)
```
We see that age has a significant effect on height at $p = .013$. We have an $R^2$ of .238, meaning this model accounts for about 24% of the variance seen in the data.

To run an ANOVA we simple run

```{r}
anova(fit1)
```

Where we see the exact same results (remembering that $F_{1,23} = (t_{23})^2$) We can also calculate the effect size, $\eta^2$, as a ratio of the effect explained by the variance measured. In this case, we divide the sum of squares of age by the sum of squares total:

$\frac{SS_{age}}{SS_{age}+SS_{error}} = \frac{124.8}{124.8+399.2} = .238$

We can interpret this as saying that 23.8% of our effect was determined by age, and the remaining was accounted for by unknown variance.

This is all pretty noisy. All things considered, there are a lot of differences between age groups that are still unaccounted for. Age probably does explain a lot here, but what about individual differences between children?

## Repeated Measures Regression

Regression assumes independence between data points (i.e., that measures were randomly sampled from the same distribution and to the best of our knowledge are not related in any other way). We would then assume that any variance not explained by our model is "noise" -- although let it be said that one man's noise is another man's avenvue for exploration.

But what if our data isn't independent? What if our scores were actually taken from five children over the coarse of five years? Accounting for the variation within a single individual can account for a great deal of the overall variation in the population. Think of it this way: there are as many different reasons why child A might be taller than child B, it just happens that we know their ages and that age is a strong predictor of height. But it could be that child A eats more spinach or that child B comes from a relatively short family. However, if we measure child A **twice** at two different time points, we know that everything about that child's personal history at time 1 is true of the child at time 2, accounting for a huge amount of unknown and potentially confounding factors. We can infer that something different between time 1 and time 2 accounts for the differences in measurement.

Repeated-measures analysis is an absolute asset for studying human behavior, as it radically reduces the number of measurements we need to take to understand the impact of a stimulus. It's not a perfect fix -- as we'll address below -- but it's loads better than assuming independence when we know some unknown factors may be influencing our result.

Let's begin by adding a third measure of child identity. *NOTE*: Even though we're giving subjects numerical values, it is important that we tell R they are factors (categorical variables where numerical values are nominal only). R assums strings are categorical factors by default. We'll then bind these factors into a single dataframe for easy analysis.

```{r}
subject <- factor(
           c(1,2,3,4,5,
             1,2,3,4,5,
             1,2,3,4,5,
             1,2,3,4,5,
             1,2,3,4,5))

hdata <- data.frame(subject,age,height)
head(hdata)
```

We can now use our knowledge of subject identity to account for variance within measures. Here, we'll use a *random-effects regression* also known as a *heirarchical linear model* or *multilevel model* to account for the effects of age nested within each individual subject.

```{r}
library(nlme)
fit2 <- lme(height ~ age,
            random = ~1 | subject/age,
            data = hdata, method = "ML")
summary(fit2)
```

The important line for most people will be the fixed-effects line, where we see a significant effect of age.

Importantly, we can also do this using a more familiar ANOVA approach. We can either print our output in ANOVA-friendly format...

```{r}
anova(fit2)
```

Two points: *$p$ values are not a measure of magnitude of significance*. A $p$ of .001 is not 10 times as significant as $p$ of .01. These values have a whole lot of baggage attached to them which I'll hopefully tackle in a future post, but suffice it to say that what we should be looking at is effect size. It's a little harder to identify effect size in random-effects regression, but thankfully there's an R package to do it for us. The MuMIn package has excellent documentation, so I'll let it speak for itself, but below we calculate the *marginal* $R^2$ (i.e., the variance explained by fixed factors) and *conditional* $R^2$ (i.e., the variance explained by the entire model of fixed and random factors)

```{r}
library(MuMIn)
r.squaredGLMM(fit2)
```

We see that our full model accounts for a whopping 97.2% of the variance!

## Adding fixed-effects variabes

Alright, now let's further say we know one more thing about our subjects: their sex. We know from everyday experience that men tend to be taller than women on average. Let's see what happens when we add an additional factor of sex to the model. The prediction of a continuous value from a continuous and a categorical variable is called an analysis of covariance or *ANCOVA*, but it is also known as a multilevel model with fixed-effects. It will be your best friend.

```{r}
sex     <- c("M","F","M","F","F",
             "M","F","M","F","F",
             "M","F","M","F","F",
             "M","F","M","F","F",
             "M","F","M","F","F")


hdata <- data.frame(subject,age,height,sex)
head(hdata)
```

```{r}
fit3 <- lme(height ~ age*sex,
            random = ~ 1 | subject/age,
            method = "ML",
            data=hdata)
summary(fit3)
```

We again find our significant effect of age, but that some of this variance is also accounted for by a significant decrease in the height between females and males ("sexM" indicates that we're comparing M to the baseline, which by default is the first factor alphabetically). We also find a significant interaction.

## Paired Comparisons (In Progress)

We know there is an interaction, but the output alone will not tell us the direction of the effect. Rather than run a series of t-tests, we need to account for familywise error rate with a single algorithm.

FWER's deserve their own entry at some point, but basically when you make a comparison against chance at the .05 level, you're actually saying that the probability that a distribution is due to chance is 1/20. By logical extention, if you run 20 tests on a completely random set of data, one of those 20 tests will be significant through sheer dumb luck. Again, massive simplification, but FWER controls for the "dumb luck" factor of making multiple comparisons.

First, let's visualize our mean differences.
```{r}
qplot(x = age, y = height, color = sex,geom = "point") + geom_smooth(method='lm')
```

This gives us a pretty clear idea of what our interaction looks like: a significant increase in height by age that increases more for males than females. With factors that have only two levels, we really don't need multiple comparison testing. However, many data science projects have dozens of levels, and we'd like to know how groups distinguish themselves. Below is code for running multiple comparisons using the Tukey method. It won't work for a factor with two levels, but it might help you in the future.

```{r, eval = FALSE}
library(multcomp)

posthoc <- glht(fit3, mcp(sex = "Tukey"))
summary(posthoc)

```
